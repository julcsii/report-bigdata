Big data is often defined by three main characteristics: volume, velocity and variety of the data. These features also define the data captured in the telecommunications network.

Processing CDR data is not straightforward and it can present challenges such as temporal and spatial sparseness. Also the different networks from different providers do not always provide the same information. There can be different fields in different formats, as there is no standardization implemented yet. 

Since the size of CDR data sets can be extremely large, it can no longer be processed by a single machine efficiently. Therefore it is of high importance to have the proper processing infrastructure in place.  

Due to the fact that big data technologies are emerging, it is possible to efficiently process large data sets for different use cases in the telecommunications domain like network anomaly detection, customer behavior analysis, traffic monitoring and so on.

The main research question can be formulated as follows:\\

\textit{How can we efficiently process and analyze large data sets captured in the mobile networks?}\\

Such data sets can be sequences of mobile network events generated by users (CDR data) and cell tower data (cell map) to obtain location information for the connected cells.

More specifically, given a sequence of mobile network events $E = \langle e_{1}, e_{2}, .., e_{n} \mid n > 0 \rangle$ and a set of cell towers $C = \set{c_{1}, c_{2}, .., c_{m} \mid m > 0}$ we want to calculate $D(T,\Tilde{T})$, the distance of the real trajectory of events $T$ and the approximated trajectory $\Tilde{T}$.






