\subsection{Experimental setup}
The experiments were executed in a Mac Book Pro with the following characteristics: 2,6 GHz Intel Core i5, 8 GB 1600 MHz DDR3 memory and 256 GB of storage.

\subsection{Analysis}
Data set coming from previous steps are used as an input for the calculations in the analysis. These are some of the most relevant features:
\begin{itemize}
    \item system\_time - timestamp of the recording
    \item cell\_loc - event's approximated location
    \item gps\_loc - event's GPS location, considered as ground truth
\end{itemize}

The analysis phase is executed with a following steps:
\begin{enumerate}
    \item Import Parquet data to pySpark DataFrame
    \item Generated and display histograms on pairwise distances
    \item Calculate descriptive statistics on pairwise distances:
        \begin{itemize}
            \item min
            \item max
            \item sum
            \item mean
            \item standard deviation
        \end{itemize}
    \item Calculate Euclidean distance measure on trajectories
    \item Visualize on map
\end{enumerate}

\subsection{Results}
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.45\textwidth]{images/histogram.png}
    \caption{Histogram of distances using OpenCelliD cell map}
    \label{fig:hist_opencell}
\end{figure}

Looking at the histograms of the pairwise Haversine distances between GPS location points and CDR location point on Figure \ref{fig:hist_opencell}, we can say that for 3G events the majority of the distances fall into the 250-500 meters range. For 2G events, the quality of the event positioning is worse, the majority of events are localized with more than 1000 meters accuracy. Here the distance is maximum two kilometers, due to the threshold we used for joining the CDR data with the cellmap data.

Overall around the half of the CDR events are positioned with less than 500 meters error. This result can change depending on individual customer's mobile usage habits, network characteristics, cell map data source and the customer's geographical position.

From the results in Table \ref{tab:dist_stats}, we can conclude that the overall positioning needs a lot of improvement, as the Euclidean distance is more than 150 kilometers. The reason why this measure is this high is the fact that the square operation in Euclidean distance tends to penalize large distances. The maximum is only around 1.6 kilometers, which does not seem to be extremely high, but this is only because the observations with higher distances are filtered out when joining the CDR and cellmap data sets. 
The 1.40 meters minimum distance is very low, so it means that for some observations the positioning was very accurate. This would probably happen when the user was very close to the cell tower they connected to. 

\begin{table}[h]
    \centering
    \begin{tabular}{|l|c|}
        \hline 
        count & $27680$ \\
        \hline
        Euclidean dist & $159402.67$ \\
        \hline
        min(dist) &  $1.40$\\
        \hline
        max(dist) &   $1652.51$\\
        \hline
        avg(dist) &  $842.40$\\
        \hline
        stddev(dist) &  $456.43$\\
        \hline
    \end{tabular}
    \caption{Descriptive statistics of Haversine distances (in meters)}
    \label{tab:dist_stats}
\end{table}

When the user is located between several cell towers, the connection can be passed from one tower to another depending on network traffic fluctuations and other factors. This phenomenon is often referred to as cell tower ping-pong handover. It can however be used for improving positioning and identifying points-of-interest (POIs). As seen in Figure \ref{fig:ping-pong}, the phone connects to a cell tower and to another one and then back again to the previous one. Without knowing the actual GPS position we could better approximate the location of the customer using the ping-pong handover schema.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{images/ping-pong.png}
    \caption{Cell ping-pong handover problem, GPS points color based on the connected cell tower}
    \label{fig:ping-pong}
\end{figure}

This method can be further improved if we take into account the angle of the antennas on the cell towers. If we know which antenna is getting the signal, we can guess the direction of the transmitting cell phone and the signal strength can give an approximation of how far away it is. This method is called cell tower triangulation and can be quite accurate in rural regions with more cell towers. However the information about the angles of the antennas and the signal strength can be outdated or even missing therefore it is not always applicable. In this analysis we did not obtain robust data about the positions of the antennas and the signal strength for each CDR event.

Positioning could be improved by reconstructing trajectories considering the road network of Berlin and the potential speed of the movement instead of simply assigning the the cell location from the cell map data.

We identified three major external factors defining the accuracy of the positioning:
\begin{itemize}
    \item individual mobile usage habits affecting the sparsity of CDR data,
    \item geographical location, as rural and urban areas has different cell size and therefore location defines the accuracy of cell tower localization and
    \item cellular network characteristics that define the overall data quality and the available attributes in the CDR data-set.
\end{itemize}


\subsection{Performance tests}
In this section we compare the run-time of the tasks using different Spark standalone clusters and different data sources, namely comma separated value files and Parquet files. The specifications of the clusters are shown in Table \ref{tab:spec}

The selected data-sets for the experiments are:
\begin{itemize}
    \item OpenCelliD data-set: 3.1 GB in .csv  and 1.04GB in Parquet format
    \item CDR data-set: 48MB in .csv and 1.94MB in Parquet format
\end{itemize}

The operations executed in the experiment are the most common transformations within the project, such as filtering and joining. Since Spark applications are lazily evaluated, a count() operation was called on the resulting DataFrames to reliably reflect the execution time.

\begin{table}[h]
    \centering
    \resizebox{0.45\textwidth}{!}{%
    \begin{tabular}{|l|c|c|}
    	\hline
         & \textbf{Baseline} & \textbf{Alternative} \\
        \hline 
        \# of workers & 1 & 2 \\
        \hline
        Worker cores  & 1 & 1 \\
        \hline
        Worker memory & 1GB & 2GB  \\
        \hline
        Driver memory & 1GB & 1GB \\
        \hline
        Executor memory & 512MB & 1GB\\
        \hline
    \end{tabular}}
    \caption{Specifications of test clusters}
    \label{tab:spec}
\end{table}

Worker memory is the total amount of memory and worker core is the number of cores Spark applications are allowed to use on the machine. Driver memory refers to the amount of memory to use for the driver process, which is where the SparkContext is initialized. Spark executor memory is the amount of memory to use per executor process. 
\cite{spark:rdds}

\subsection{Results}
The execution time of different processing tasks on DataFrame created from the OpenCelliD cell map data-set can be seen in Table \ref{tab:res}.

\begin{table}[h]
    \centering
    \resizebox{0.45\textwidth}{!}{%
    \begin{tabular}{|l||c|c|c|c|}
    	\hline
        \textbf{Task name} & \multicolumn{2}{c|}{\textbf{Baseline}} & \multicolumn{2}{c|}{\textbf{Alternative}}\\
        \hline
        \textit{Data source} & \textit{parquet} & \textit{.csv} & \textit{parquet} & \textit{.csv} \\
        \hline 
        \hline
        read\_data() & 5.27 & 130.68 & 7.19 &  91.6 \\
        \hline
        min\_of\_col() & 13.47 & 65.17 & 14.39 & 44.31 \\
        \hline
        sort\_by\_col() & 55.67 & 168.12 & 59.56  & 112.05 \\
        \hline
        filter\_by\_col() & 2.81 & 67.82 & 4.45  & 46.19 \\
        \hline
        join\_dfs() & 18.66 & 104.05 & 18.15 & 86.06 \\
        \hline
        collect\_rows() & 1.93 & -\footnotemark & 2.12 & -\footnotemark \\
        \hline
        \textbf{Total} & \textbf{97.82} & \textbf{536.84} & \textbf{105.86} & \textbf{380.65} \\
        \hline
    \end{tabular}}
    \caption{Run-times of data processing tasks with different test clusters in seconds}
    \label{tab:res}
\end{table}
\footnotetext{Running collect\_rows() method,'java.lang.OutOfMemoryError: Java heap space' occurs.}
\footnotetext{Running collect\_rows() method,'ConnectionRefusedError' occurs, indicating that an error occurred while trying to connect to the Java server.}

During the experiments we saw that reading data to pySpark DataFrames from Parquet files is more time-efficient than from .csv files, which is in line with our expectations.

The total execution-time in case of Parquet data-source on the Baseline cluster is slightly less then on the Alternate cluster. Since the size of the files is not too large, the benefit of increasing number of workers and their memory could be neutralized by the communication overhead between workers. Instead of adding one more worker, it makes more sense to increase the memory of the existing worker or add more cores. However for large clusters with several physical machines, parallel computation with several workers can be better utilized. Since the test laptop only has 5 cores, adding more than 2 workers is problematic.

In case of .csv data-source the execution time improves by adding another worker and increasing the memory, since the size of the data is larger.

With this architecture design, it is reasonably easy to deploy the application on Amazon Web Services (AWS) or similar cloud service provider allowing scalability to process terabytes of data.